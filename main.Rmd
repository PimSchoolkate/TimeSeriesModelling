---
title: "Untitled"
author: "Pim"
date: "1/5/2023"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
serie=window(ts(read.table("RenewUSA.dat", header=F),start=1990,freq=12))
```

```{r}
plot(serie,main="Total production of renewable energy (USA)")
abline(v=1990:2020,col=4,lty=3)
```

We have a hint that variance is not constant from boxplots per year


```{r}
boxplot(serie~floor(time(serie)))
```

mean vs variance shows this better:

```{r}
groupedserie <- matrix(serie[1:(30*12)],ncol=30) #12 quarters=3yrs

m<-apply(groupedserie,2,mean)
v<-apply(groupedserie,2,var)
plot(v~m)
abline(lm(v~m),col=2,lty=3)
```

We also check it for every 3 years to be more assertive of our hypothesis:

```{r}
groupedserie <- matrix(serie[1:(36*10)],ncol=10) #12 quarters=3yrs together=ncol=12
boxplot(groupedserie)
```

confirmed by mean vs variance.

```{r}
m<-apply(groupedserie,2,mean)
v<-apply(groupedserie,2,var)
plot(v~m)
abline(lm(v~m),col=2,lty=3)
```

Thus apply log-transformation to remove variance

```{r}
lnserie=log(serie)
plot(lnserie)
abline(v=1947:2020,col=4,lty=3)
abline(h=0)
```

check again the variance

```{r}
boxplot(lnserie~floor(time(lnserie)))
```

mean vs variance shows this better:
Variance is nearly stable.
```{r}
groupedserie <- matrix(lnserie[1:(36*10)],ncol=10) #12 quarters=3yrs

boxplot(groupedserie, main="Boxplots for the log-transformed series (3-year period)")

m<-apply(groupedserie,2,mean)
v<-apply(groupedserie,2,var)
plot(v~m, main="Mean-variance plot for the log-transformed series (3-year period)")
abline(lm(v~m),col=2,lty=3)
```

```{r}
plot(lnserie)
abline(h=mean(lnserie), col="red")
```

Check for seasonality:
there seems to be a small seasonal effect of 12 months

```{r}
monthplot(lnserie, main="Monthly plot")
```

```{r}
ts.plot(matrix(lnserie,nrow=12), col=1:12, main="Plot along the months for years 1990-2020")
```

```{r}
d12lnserie <- diff(lnserie,12)
plot(d12lnserie)
abline(h=mean(d12lnserie), col="red")

monthplot(d12lnserie)
```

get the mean to be zero

```{r}
d1d12lnserie <- diff(d12lnserie)
plot(d1d12lnserie)
abline(h=mean(d1d12lnserie), col="red")
```

```{r}
d1d1d12lnserie <- diff(d1d12lnserie)
plot(d1d1d12lnserie)
abline(h=mean(d1d12lnserie), col="red")
```

d1d12lnserie is clearly the best...

```{r}
var(lnserie)
var(d12lnserie)
var(d1d12lnserie)
var(d1d1d12lnserie)
```


```{r}
t.ratio <- function(model) {
  cat("T-ratios:",round(model$coef/sqrt(diag(model$var.coef)),2), "\n")
}
```

```{r}
significance <- function(model) {
  cat("Significant?:",abs(model$coef/sqrt(diag(model$var.coef)))>2, "\n")
}
```




Seasonal:
tails off in PACF thus we have a MA(Q=1)

Non-seasonal:
so we have 
1. AR(p=2)
2. MA(q=2)
3. ARMA(p=2, q=2)

```{r}
acf(d1d12lnserie, ylim=c(-1,1), lag.max = 72,col=c(2,rep(1,11)),lwd=2)
pacf(d1d12lnserie, ylim=c(-1,1), lag.max = 72,col=c(rep(1,11),2),lwd=2)
```

ARMA(2,0)(0,1)
```{r}
ARMA.20.01 <- arima(d1d12lnserie, order=c(2,0,0), seasonal=list(order=c(0,0,1), period=12))
ARMA.20.01
```

```{r}
t.ratio(ARMA.20.01)
significance(ARMA.20.01)
```


ARMA(0,2)(0,1)
```{r}
ARMA.02.01 <- arima(d1d12lnserie, order=c(0,0,2), seasonal=list(order=c(0,0,1), period=12))
ARMA.02.01
```

```{r}
t.ratio(ARMA.02.01)
significance(ARMA.02.01)
```


ARMA(2,2)(0,1)
```{r}
ARMA.22.01 <- arima(d1d12lnserie, order=c(2,0,2), seasonal=list(order=c(0,0,1), period=12))
```

```{r}
t.ratio(ARMA.22.01)
significance(ARMA.22.01)
```

```{r}
AIC(ARMA.02.01, ARMA.20.01, ARMA.22.01)
```


ARIMA(2,1,0)(0,1,1)

```{r}
ARIMA.210.011 <- arima(lnserie, order=c(2,1,0), seasonal=list(order=c(0,1,1), period=12))
ARIMA.210.011
```

```{r}
t.ratio(ARIMA.210.011)
significance(ARIMA.210.011)
```

ARIMA(0,1,2)(0,1,1)

```{r}
ARIMA.012.011 <- arima(lnserie, order=c(0,1,2), seasonal=list(order=c(0,1,1), period=12))
ARIMA.210.011
```

```{r}
t.ratio(ARIMA.210.011)
significance(ARIMA.210.011)
```

ARIMA(2,1,2)(0,1,1)

```{r}
ARIMA.212.011 <- arima(lnserie, order=c(2,1,2), seasonal=list(order=c(0,1,1), period=12))
ARIMA.212.011
```

```{r}
t.ratio(ARIMA.212.011)
significance(ARIMA.212.011)
```

```{r}
AIC(ARMA.02.01, ARMA.20.01, ARMA.22.01, 
    ARIMA.210.011, ARIMA.012.011, ARIMA.212.011)
```

```{r, eval=F}
model_search <- function(series, p.range, q.range, P.range, Q.range) {
  aic.best = 0
  best_combination = ""
  for( p in p.range) {
    for (q in q.range) {
      for (P in P.range) {
        for (Q in Q.range) {
          # print(paste0("p=", p,
          #              " q=", q,
          #              " P=", P,
          #              " Q=", Q))
          tryCatch({aic.current = AIC(arima(series, order=c(p,1,q), seasonal = list(order=c(P, 1, Q), period=12)))}, finally = {if (aic.best > aic.current) {
            aic.best = aic.current
            best_combination = paste0("(",p,1,q,")(",P,1,Q,")")
          
          }; next})
        }
      }
    }
  }
  print(best_combination)
  print(aic.best)
}

model_search(lnserie,
             p.range = c(0,1,2),
             q.range = c(0,1,2),
             P.range = c(0,1,2),
             Q.range = c(0,1,2))
```

best model is ARIMA(0,1,2)(0,1,2)
lets check if q,Q=3 (very unlikely..)
Answer is no..

```{r}
model_search(lnserie,
             p.range = c(0),
             q.range = c(1,2,3),
             P.range = c(0),
             Q.range = c(1,2,3))
```

```{r}
ARIMA.best <- arima(lnserie, order=c(0,1,2), seasonal = list( order=c(0,1,2), period=12))
```

```{r}
AIC(ARIMA.best, ARIMA.012.011)
```

## Validation::

```{r}
#################Validation#################################
validation=function(model,dades){
  s=frequency(get(model$series))
  resid=model$residuals
  par(mfrow=c(2,2),mar=c(3,3,3,3))
  #Residuals plot
  plot(resid,main="Residuals")
  abline(h=0)
  abline(h=c(-3*sd(resid),3*sd(resid)),lty=3,col=4)
  #Square Root of absolute values of residuals (Homocedasticity)
  scatter.smooth(sqrt(abs(resid)),main="Square Root of Absolute residuals",
                 lpars=list(col=2))
  
  #Normal plot of residuals
  qqnorm(resid)
  qqline(resid,col=2,lwd=2)
  
  ##Histogram of residuals with normal curve
  hist(resid,breaks=20,freq=FALSE)
  curve(dnorm(x,mean=mean(resid),sd=sd(resid)),col=2,add=T)
  
  
  #ACF & PACF of residuals
  par(mfrow=c(1,2))
  acf(resid,ylim=c(-1,1),lag.max=60,col=c(2,rep(1,s-1)),lwd=1)
  pacf(resid,ylim=c(-1,1),lag.max=60,col=c(rep(1,s-1),2),lwd=1)
  par(mfrow=c(1,1))
  
  #ACF & PACF of square residuals 
  par(mfrow=c(1,2))
  acf(resid^2,ylim=c(-1,1),lag.max=60,col=c(2,rep(1,s-1)),lwd=1)
  pacf(resid^2,ylim=c(-1,1),lag.max=60,col=c(rep(1,s-1),2),lwd=1)
  par(mfrow=c(1,1))
  
  #Ljung-Box p-values
  par(mar=c(2,2,1,1))
  tsdiag(model,gof.lag=7*s)
  cat("\n--------------------------------------------------------------------\n")
  print(model)
  
  #Stationary and Invertible
  cat("\nModul of AR Characteristic polynomial Roots: ", 
      Mod(polyroot(c(1,-model$model$phi))),"\n")
  cat("\nModul of MA Characteristic polynomial Roots: ",
      Mod(polyroot(c(1,model$model$theta))),"\n")
  
  #Model expressed as an MA infinity (psi-weights)
  psis=ARMAtoMA(ar=model$model$phi,ma=model$model$theta,lag.max=36)
  names(psis)=paste("psi",1:36)
  cat("\nPsi-weights (MA(inf))\n")
  cat("\n--------------------\n")
  print(psis[1:20])
  
  #Model expressed as an AR infinity (pi-weights)
  pis=-ARMAtoMA(ar=-model$model$theta,ma=-model$model$phi,lag.max=36)
  names(pis)=paste("pi",1:36)
  cat("\nPi-weights (AR(inf))\n")
  cat("\n--------------------\n")
  print(pis[1:20])
  
  ## Add here complementary tests (use with caution!)
  ##---------------------------------------------------------
  cat("\nNormality Tests\n")
  cat("\n--------------------\n")
 
  
  suppressMessages(require(forecast, quietly = TRUE, warn.conflicts=FALSE))
  plot(model)
  
  ##Shapiro-Wilks Normality test
  print(shapiro.test(resid(model)))

  suppressMessages(require(nortest,quietly=TRUE,warn.conflicts=FALSE))
  ##Anderson-Darling test
  print(ad.test(resid(model)))
  
  suppressMessages(require(tseries,quietly=TRUE,warn.conflicts=FALSE))
  ##Jarque-Bera test
  print(jarque.bera.test(resid(model)))
  
  cat("\nHomoscedasticity Test\n")
  cat("\n--------------------\n")
  suppressMessages(require(lmtest,quietly=TRUE,warn.conflicts=FALSE))
  ##Breusch-Pagan test
  obs=get(model$series)
  print(bptest(resid(model)~I(obs-resid(model))))
  
  cat("\nIndependence Tests\n")
  cat("\n--------------------\n")
  
  ##Durbin-Watson test
  print(dwtest(resid(model)~I(1:length(resid(model)))))
  
  ##Ljung-Box test
  cat("\nLjung-Box test\n")
  print(t(apply(matrix(c(1:4,(1:4)*s)),1,function(el) {
    te=Box.test(resid(model),type="Ljung-Box",lag=el)
    c(lag=(te$parameter),statistic=te$statistic[[1]],p.value=te$p.value)})))
  

  #Sample ACF vs. Teoric ACF
  par(mfrow=c(2,2),mar=c(3,3,3,3))
  acf(dades, ylim=c(-1,1) ,lag.max=36,main="Sample ACF")
  
  plot(ARMAacf(model$model$phi,model$model$theta,lag.max=36),ylim=c(-1,1), 
       type="h",xlab="Lag",  ylab="", main="ACF Teoric")
  abline(h=0)
  
  #Sample PACF vs. Teoric PACF
  pacf(dades, ylim=c(-1,1) ,lag.max=36,main="Sample PACF")
  
  plot(ARMAacf(model$model$phi,model$model$theta,lag.max=36, pacf=T),ylim=c(-1,1),
       type="h", xlab="Lag", ylab="", main="PACF Teoric")
  abline(h=0)
  par(mfrow=c(1,1))
}
################# Fi Validation #################################
```

```{r}

validation(ARIMA.best, lnserie)
validation(ARIMA.012.011, lnserie)



## STABILITY TESTING

```{r}
ultim=c(2018,12)
pdq=c(0,1,2)
PDQ=c(0,1,2)

serie2=window(serie,end=ultim)
lnserie2=log(serie2)
serie1=window(serie,end=ultim+c(1,0))
lnserie1=log(serie1)

(modA=arima(lnserie1,order=pdq,seasonal=list(order=PDQ,period=12)))
(modB=arima(lnserie2,order=pdq,seasonal=list(order=PDQ,period=12)))
```

```{r}
pred=predict(modB,n.ahead=12)
pr<-ts(c(tail(lnserie2,1),pred$pred),start=ultim,freq=12)
se<-ts(c(0,pred$se),start=ultim,freq=12)

#Intervals
tl<-ts(exp(pr-1.96*se),start=ultim,freq=12)
tu<-ts(exp(pr+1.96*se),start=ultim,freq=12)
pr<-ts(exp(pr),start=ultim,freq=12)

ts.plot(serie,tl,tu,pr,
        lty=c(1,2,2,1),
        col=c(1,4,4,2),
        lwd=2,
        xlim=ultim[1]+c(-2,+2),
        type="o",
        main=paste("Model ARIMA(",
                   paste(pdq,collapse=","),")(",
                   paste(PDQ,collapse=","),")12",sep=""))
abline(v=(ultim[1]-2):(ultim[1]+2),lty=3,col=4)
legend(x="bottomleft", c("Timeseries", "Lower CI", "Upper CI", "Prediction"), col=c(1,4,4,2), lwd=2, lty=c(1,2,2,1))
```

checking
```{r}
(previs=window(cbind(tl,pr,tu,serie,error=round(serie-pr,3)),start=ultim))
```

metrics
```{r}
obs=window(serie,start=ultim)
mod.RMSE1=sqrt(sum((obs-pr)^2)/12)
mod.MAE1=sum(abs(obs-pr))/12
mod.RMSPE1=sqrt(sum(((obs-pr)/obs)^2)/12)
mod.MAPE1=sum(abs(obs-pr)/obs)/12

data.frame("RMSE"=mod.RMSE1,"MAE"=mod.MAE1,"RMSPE"=mod.RMSPE1,"MAPE"=mod.MAPE1)
```



```{r}
mCI1=mean(tu-tl)

cat("\nMean Length CI: ",mCI1)
```


Repeat for ARIMA(0,1,2)(0,1,1)
```{r}
ultim=c(2018,12)
pdq=c(0,1,2)
PDQ=c(0,1,1)

serie2=window(serie,end=ultim)
lnserie2=log(serie2)
serie1=window(serie,end=ultim+c(1,0))
lnserie1=log(serie1)

(modA=arima(lnserie1,order=pdq,seasonal=list(order=PDQ,period=12)))
(modB=arima(lnserie2,order=pdq,seasonal=list(order=PDQ,period=12)))
```

```{r}
pred=predict(modB,n.ahead=12)
pr<-ts(c(tail(lnserie2,1),pred$pred),start=ultim,freq=12)
se<-ts(c(0,pred$se),start=ultim,freq=12)

#Intervals
tl<-ts(exp(pr-1.96*se),start=ultim,freq=12)
tu<-ts(exp(pr+1.96*se),start=ultim,freq=12)
pr<-ts(exp(pr),start=ultim,freq=12)

ts.plot(serie,tl,tu,pr,
        lty=c(1,2,2,1),
        col=c(1,4,4,2),
        lwd=2,
        xlim=ultim[1]+c(-2,+2),
        type="o",
        main=paste("Model ARIMA(",
                   paste(pdq,collapse=","),")(",
                   paste(PDQ,collapse=","),")12",sep=""))
abline(v=(ultim[1]-2):(ultim[1]+2),lty=3,col=4)
legend(x="bottomleft", c("Timeseries", "Lower CI", "Upper CI", "Prediction"), col=c(1,4,4,2), lwd=2, lty=c(1,2,2,1))
```

checking
```{r}
(previs=window(cbind(tl,pr,tu,serie,error=round(serie-pr,3)),start=ultim))
```

metrics
```{r}
obs=window(serie,start=ultim)
mod.RMSE1=sqrt(sum((obs-pr)^2)/12)
mod.MAE1=sum(abs(obs-pr))/12
mod.RMSPE1=sqrt(sum(((obs-pr)/obs)^2)/12)
mod.MAPE1=sum(abs(obs-pr)/obs)/12

data.frame("RMSE"=mod.RMSE1,"MAE"=mod.MAE1,"RMSPE"=mod.RMSPE1,"MAPE"=mod.MAPE1)
```



```{r}
mCI1=mean(tu-tl)

cat("\nMean Length CI: ",mCI1)
```


## PREDICTION


```{r}
start = c(2019,12)
pred=predict(ARIMA.best,n.ahead=12)
pr<-ts(c(tail(lnserie,1),pred$pred),start=start,freq=12)
se<-ts(c(0,pred$se),start=start,freq=12)

#Intervals
tl1<-ts(exp(pr-1.96*se),start=start,freq=12)
tu1<-ts(exp(pr+1.96*se),start=start,freq=12)
pr1<-ts(exp(pr),start=start,freq=12)

ts.plot(serie,tl1,tu1,pr1,
        lty=c(1,2,2,1),
        col=c(1,4,4,2),
        lwd=2,
        xlim=ultim[1]+c(-2,+3),
        type="o",
        main=paste("Model ARIMA(",
                   paste(pdq,collapse=","),")(",
                   paste(PDQ,collapse=","),")12",sep=""))
abline(v=(ultim[1]-2):(ultim[1]+3),lty=3,col=4)
legend(x="bottomleft", c("Timeseries", "Lower CI", "Upper CI", "Prediction"), col=c(1,4,4,2), lwd=2, lty=c(1,2,2,1))
```


```{r}
(previs1=window(cbind(tl1,pr1,tu1),start=ultim+c(1,0)))
```


Just checking that the stability test and prediction are not the same... they look very similar

```{r}
pred=predict(modB,n.ahead=12)
pr<-ts(c(tail(lnserie2,1),pred$pred),start=ultim,freq=12)
```

```{r}
pred=predict(ARIMA.best,n.ahead=12)
pr.test<-ts(c(tail(lnserie,1),pred$pred),start=ultim,freq=12)

pr - pr.test
```

```{r}
obs=window(serie,start=ultim)
mod.RMSE1=sqrt(sum((obs-pr)^2)/12)
mod.MAE1=sum(abs(obs-pr))/12
mod.RMSPE1=sqrt(sum(((obs-pr)/obs)^2)/12)
mod.MAPE1=sum(abs(obs-pr)/obs)/12

data.frame("RMSE"=mod.RMSE1,"MAE"=mod.MAE1,"RMSPE"=mod.RMSPE1,"MAPE"=mod.MAPE1)
```



## OUTLIERS

```{r}
source("atipics2.r")

##Detection of outliers: In this case, we have applied a regular and a seasonal differentiation of order $S=12$. We set the criterion to $crit = 2.8$ and also the argument LS to TRUE.
## The crit value chosen by the researcher is typically fixed around 3; the LS argument is optional (= TRUE if one aims to detect a level shift)

ARIMA.atip=outdetec(ARIMA.best,dif=c(1,12),crit=2.8,LS=T) # automatic detection of outliers with crit=2.8 and LS =TRUE

#Estimated residual variance after outliers detection and treatment
ARIMA.atip$sigma
```

```{r}
atipics=ARIMA.atip$atip[order(ARIMA.atip$atip[,1]),]
months=c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")

data.frame(atipics,Date=paste(months[(atipics[,1]-1)%%12+1],start(lnserie)[1]+((atipics[,1]-1)%/%12)),perc.Obs=exp(atipics[,3])*100)
```

```{r}
lnserie.lin=lineal(lnserie,ARIMA.atip$atip)
serie.lin=exp(lnserie.lin)

plot(serie.lin,col=2)
lines(serie)
abline(v=1990:2020, col="gray",lty=3)
legend(x="topleft", legend=c("Without Outliers", "With Outliers"), col=c(2,1), lwd=2)
```

```{r}
plot(lnserie-lnserie.lin)
```

```{r}
d1d12lnserie.lin=diff(diff(lnserie.lin,12))
par(mfrow=c(1,2))
acf(d1d12lnserie.lin,ylim=c(-1,1),lag.max=72,col=c(2,rep(1,11)),lwd=2)
pacf(d1d12lnserie.lin,ylim=c(-1,1),lag.max=72,col=c(rep(1,11),2),lwd=2)

par(mfrow=c(1,1))
```

```{r}
(ARIMA.lin=arima(lnserie.lin,order=c(0,1,2),seasonal=list(order=c(0,1,2),period=12)))
ARIMA.best
```

```{r}
validation(ARIMA.lin, lnserie.lin)
```

## Check for stability

```{r}
ultim=c(2018,12)
pdq=c(0,1,1)
PDQ=c(2,1,0)

serie1.lin=window(serie.lin,end=ultim+c(1,0))
lnserie1.lin=log(serie1.lin)
serie2.lin=window(serie.lin,end=ultim)
lnserie2.lin=log(serie2.lin)

(mod.lin=arima(lnserie1.lin,order=pdq,seasonal=list(order=PDQ,period=12)))
(mod2.lin=arima(lnserie2.lin,order=pdq,seasonal=list(order=PDQ,period=12)))
```

```{r}
pred=predict(mod2,n.ahead=12)
pr<-ts(c(tail(lnserie2,1),pred$pred),start=ultim,freq=12)
se<-ts(c(0,pred$se),start=ultim,freq=12)

#Intervals
tl<-ts(exp(pr-1.96*se),start=ultim,freq=12)
tu<-ts(exp(pr+1.96*se),start=ultim,freq=12)
pr<-ts(exp(pr),start=ultim,freq=12)

ts.plot(serie,tl,tu,pr,
        lty=c(1,2,2,1),
        col=c(1,4,4,2),
        lwd=2,
        xlim=ultim[1]+c(-2,+2),
        type="o",
        main=paste("Model ARIMA(",
                   paste(pdq,collapse=","),")(",
                   paste(PDQ,collapse=","),")12",sep=""))
abline(v=(ultim[1]-2):(ultim[1]+2),lty=3,col=4)
legend(x="bottomleft", c("Timeseries", "Lower CI", "Upper CI", "Prediction"), col=c(1,4,4,2), lwd=2, lty=c(1,2,2,1))
```

```{r}
(previs.lin=window(cbind(tl,pr,tu,serie,error=round(serie-pr,3)),start=ultim))
```

```{r}
obs=window(serie,start=ultim)
mod.RMSE2=sqrt(sum((obs-pr)^2)/12)
mod.MAE2=sum(abs(obs-pr))/12
mod.RMSPE2=sqrt(sum(((obs-pr)/obs)^2)/12)
mod.MAPE2=sum(abs(obs-pr)/obs)/12

data.frame("RMSE"=mod.RMSE2,"MAE"=mod.MAE2,"RMSPE"=mod.RMSPE2,"MAPE"=mod.MAPE2)
```

```{r}
mCI2=mean(tu-tl)

cat("\nMean Length CI: ",mCI2)
```



## OUTLIER PREDICTION


```{r}
start = c(2019,12)
pred=predict(ARIMA.lin,n.ahead=12)
pr<-ts(c(tail(lnserie,1),pred$pred),start=start,freq=12)
se<-ts(c(0,pred$se),start=start,freq=12)

#Intervals
tl2<-ts(exp(pr-1.96*se),start=start,freq=12)
tu2<-ts(exp(pr+1.96*se),start=start,freq=12)
pr2<-ts(exp(pr),start=start,freq=12)

ts.plot(serie,tl2,tu2,pr2,
        lty=c(1,2,2,1),
        col=c(1,4,4,2),
        lwd=2,
        xlim=ultim[1]+c(-2,+3),
        type="o",
        main=paste("Model ARIMA(",
                   paste(pdq,collapse=","),")(",
                   paste(PDQ,collapse=","),")12",sep=""))
abline(v=(ultim[1]-2):(ultim[1]+3),lty=3,col=4)
legend(x="bottomleft", c("Timeseries", "Lower CI", "Upper CI", "Prediction"), col=c(1,4,4,2), lwd=2, lty=c(1,2,2,1))
```

```{r}
(previs2=window(cbind(tl2,pr2,tu2),start=ultim+c(1,0)))
```

```{r}
cbind(previs1,previs2)
```

```{r}
ts.plot(serie,tl1,tu1,pr1,tl2,tu2,pr2,lty=c(1,2,2,1,2,2,1),lwd=2,col=c(1,4,4,2,3,3,6),xlim=ultim[1]+c(1,3),type="o",main="AIRBCN")
legend("bottomleft",c("95% CI - \t ARIMA(0,1,2)(0,1,2)12","Prediction - \t ARIMA(0,1,2)(0,1,2)12","95% CI - \t ARIMA(0,1,2)(0,1,2)12 with outlier treatment","Prediction - \t ARIMA(0,1,2)(0,1,2)12 with outlier treatment"),col=c(4,2,3,6),lty=1,lwd=2)
abline(v=ultim[1]+1:3,lty=3,col=4)
```


